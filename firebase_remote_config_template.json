{
    "conditions": [
        {
            "name": "development_env",
            "expression": "app.id.contains('dev')",
            "tagColor": "BLUE"
        },
        {
            "name": "premium_users",
            "expression": "app.userProperty['tier'] == 'premium'",
            "tagColor": "GREEN"
        },
        {
            "name": "debug_mode_users",
            "expression": "percent <= 5",
            "tagColor": "ORANGE"
        }
    ],
    "parameters": {
        "active_ai_model_type": {
            "defaultValue": {
                "value": "gemini_with_system_instructions"
            },
            "description": "Active AI model type - determines which model configuration to use and whether system instructions are supported",
            "valueType": "STRING",
            "conditionalValues": {
                "development_env": {
                    "value": "gemini_with_system_instructions"
                }
            }
        },
        "ai_gemini_model": {
            "defaultValue": {
                "value": "gemini-2.5-flash"
            },
            "description": "Primary Gemini model for text analysis and processing",
            "valueType": "STRING",
            "conditionalValues": {
                "premium_users": {
                    "value": "gemini-1.5-pro"
                }
            }
        },
        "ai_gemini_image_model": {
            "defaultValue": {
                "value": "gemini-2.0-flash-preview-image-generation"
            },
            "description": "Gemini model for image generation and processing",
            "valueType": "STRING"
        },
        "ai_temperature": {
            "defaultValue": {
                "value": "0.4"
            },
            "description": "Controls creativity vs consistency (0.0-1.0). Lower = more focused, Higher = more creative",
            "valueType": "NUMBER",
            "conditionalValues": {
                "development_env": {
                    "value": "0.8"
                }
            }
        },
        "ai_max_output_tokens": {
            "defaultValue": {
                "value": "1024"
            },
            "description": "Maximum tokens in AI response. Higher = longer responses",
            "valueType": "NUMBER",
            "conditionalValues": {
                "premium_users": {
                    "value": "2048"
                }
            }
        },
        "ai_top_k": {
            "defaultValue": {
                "value": "40"
            },
            "description": "Top-K sampling parameter. Lower = more focused responses",
            "valueType": "NUMBER"
        },
        "ai_top_p": {
            "defaultValue": {
                "value": "0.95"
            },
            "description": "Top-P (nucleus) sampling parameter. Lower = more focused responses",
            "valueType": "NUMBER"
        },

        "ai_request_timeout_seconds": {
            "defaultValue": {
                "value": "30"
            },
            "description": "Timeout for AI requests in seconds",
            "valueType": "NUMBER",
            "conditionalValues": {
                "development_env": {
                    "value": "60"
                }
            }
        },
        "ai_enable_advanced_features": {
            "defaultValue": {
                "value": "true"
            },
            "description": "Enable experimental AI features",
            "valueType": "BOOLEAN"
        },
        "ai_debug_mode": {
            "defaultValue": {
                "value": "false"
            },
            "description": "Enable detailed logging for AI operations",
            "valueType": "BOOLEAN",
            "conditionalValues": {
                "development_env": {
                    "value": "true"
                },
                "debug_mode_users": {
                    "value": "true"
                }
            }
        }
    },
    "parameterGroups": {
        "AI Model Configuration": {
            "description": "Core AI model selection and configuration parameters",
            "parameters": {
                "ai_gemini_model": {
                    "defaultValue": {
                        "value": "gemini-2.5-flash"
                    },
                    "description": "Primary Gemini model for text analysis and processing",
                    "valueType": "STRING",
                    "conditionalValues": {
                        "premium_users": {
                            "value": "gemini-1.5-pro"
                        }
                    }
                },
                "ai_gemini_image_model": {
                    "defaultValue": {
                        "value": "gemini-2.0-flash-preview-image-generation"
                    },
                    "description": "Gemini model for image generation and processing",
                    "valueType": "STRING"
                }
            }
        },
        "Generation Parameters": {
            "description": "AI generation and sampling parameters for fine-tuning response quality",
            "parameters": {
                "ai_temperature": {
                    "defaultValue": {
                        "value": "0.4"
                    },
                    "description": "Controls creativity vs consistency (0.0-1.0). Lower = more focused, Higher = more creative",
                    "valueType": "NUMBER",
                    "conditionalValues": {
                        "development_env": {
                            "value": "0.8"
                        }
                    }
                },
                "ai_max_output_tokens": {
                    "defaultValue": {
                        "value": "1024"
                    },
                    "description": "Maximum tokens in AI response. Higher = longer responses",
                    "valueType": "NUMBER",
                    "conditionalValues": {
                        "premium_users": {
                            "value": "2048"
                        }
                    }
                },
                "ai_top_k": {
                    "defaultValue": {
                        "value": "40"
                    },
                    "description": "Top-K sampling parameter. Lower = more focused responses",
                    "valueType": "NUMBER"
                },
                "ai_top_p": {
                    "defaultValue": {
                        "value": "0.95"
                    },
                    "description": "Top-P (nucleus) sampling parameter. Lower = more focused responses",
                    "valueType": "NUMBER"
                }
            }
        },

        "Performance & Control": {
            "description": "Performance settings and feature flags for AI operations",
            "parameters": {
                "ai_request_timeout_seconds": {
                    "defaultValue": {
                        "value": "30"
                    },
                    "description": "Timeout for AI requests in seconds",
                    "valueType": "NUMBER",
                    "conditionalValues": {
                        "development_env": {
                            "value": "60"
                        }
                    }
                },
                "ai_enable_advanced_features": {
                    "defaultValue": {
                        "value": "true"
                    },
                    "description": "Enable experimental AI features",
                    "valueType": "BOOLEAN"
                },
                "ai_debug_mode": {
                    "defaultValue": {
                        "value": "false"
                    },
                    "description": "Enable detailed logging for AI operations",
                    "valueType": "BOOLEAN",
                    "conditionalValues": {
                        "development_env": {
                            "value": "true"
                        },
                        "debug_mode_users": {
                            "value": "true"
                        }
                    }
                }
            }
        }
    }
}